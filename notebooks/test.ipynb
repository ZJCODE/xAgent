{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1be612b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Ensure the xAgent package is in the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "677b0f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResponseCreatedEvent(response=Response(id='resp_6899a27338d08198b009237fc875dc790c083d2351948b56', created_at=1754899059.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4.1-mini-2025-04-14', object='response', output=[], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), safety_identifier=None, service_tier='auto', status='in_progress', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=None, user=None, store=True), sequence_number=0, type='response.created')\n",
      "ResponseInProgressEvent(response=Response(id='resp_6899a27338d08198b009237fc875dc790c083d2351948b56', created_at=1754899059.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4.1-mini-2025-04-14', object='response', output=[], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), safety_identifier=None, service_tier='auto', status='in_progress', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=None, user=None, store=True), sequence_number=1, type='response.in_progress')\n",
      "ResponseOutputItemAddedEvent(item=ResponseOutputMessage(id='msg_6899a2736ea0819899639402af56dd710c083d2351948b56', content=[], role='assistant', status='in_progress', type='message'), output_index=0, sequence_number=2, type='response.output_item.added')\n",
      "ResponseContentPartAddedEvent(content_index=0, item_id='msg_6899a2736ea0819899639402af56dd710c083d2351948b56', output_index=0, part=ResponseOutputText(annotations=[], text='', type='output_text', logprobs=[]), sequence_number=3, type='response.content_part.added')\n",
      "ResponseTextDeltaEvent(content_index=0, delta='Hello', item_id='msg_6899a2736ea0819899639402af56dd710c083d2351948b56', logprobs=[], output_index=0, sequence_number=4, type='response.output_text.delta', obfuscation='HM3RR6clALk')\n",
      "ResponseTextDeltaEvent(content_index=0, delta='!', item_id='msg_6899a2736ea0819899639402af56dd710c083d2351948b56', logprobs=[], output_index=0, sequence_number=5, type='response.output_text.delta', obfuscation='s2adpDhLbCqTF5a')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' How', item_id='msg_6899a2736ea0819899639402af56dd710c083d2351948b56', logprobs=[], output_index=0, sequence_number=6, type='response.output_text.delta', obfuscation='nqztzDdIxDdV')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' can', item_id='msg_6899a2736ea0819899639402af56dd710c083d2351948b56', logprobs=[], output_index=0, sequence_number=7, type='response.output_text.delta', obfuscation='neYm9740Jhgj')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' I', item_id='msg_6899a2736ea0819899639402af56dd710c083d2351948b56', logprobs=[], output_index=0, sequence_number=8, type='response.output_text.delta', obfuscation='xgsEbNAa1U2wXs')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' assist', item_id='msg_6899a2736ea0819899639402af56dd710c083d2351948b56', logprobs=[], output_index=0, sequence_number=9, type='response.output_text.delta', obfuscation='CizrvKns4')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' you', item_id='msg_6899a2736ea0819899639402af56dd710c083d2351948b56', logprobs=[], output_index=0, sequence_number=10, type='response.output_text.delta', obfuscation='uaRcwuZhA9gw')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' today', item_id='msg_6899a2736ea0819899639402af56dd710c083d2351948b56', logprobs=[], output_index=0, sequence_number=11, type='response.output_text.delta', obfuscation='IleicTMNy0')\n",
      "ResponseTextDeltaEvent(content_index=0, delta='?', item_id='msg_6899a2736ea0819899639402af56dd710c083d2351948b56', logprobs=[], output_index=0, sequence_number=12, type='response.output_text.delta', obfuscation='iPouzUUPBKvITQU')\n",
      "ResponseTextDoneEvent(content_index=0, item_id='msg_6899a2736ea0819899639402af56dd710c083d2351948b56', logprobs=[], output_index=0, sequence_number=13, text='Hello! How can I assist you today?', type='response.output_text.done')\n",
      "ResponseContentPartDoneEvent(content_index=0, item_id='msg_6899a2736ea0819899639402af56dd710c083d2351948b56', output_index=0, part=ResponseOutputText(annotations=[], text='Hello! How can I assist you today?', type='output_text', logprobs=[]), sequence_number=14, type='response.content_part.done')\n",
      "ResponseOutputItemDoneEvent(item=ResponseOutputMessage(id='msg_6899a2736ea0819899639402af56dd710c083d2351948b56', content=[ResponseOutputText(annotations=[], text='Hello! How can I assist you today?', type='output_text', logprobs=[])], role='assistant', status='completed', type='message'), output_index=0, sequence_number=15, type='response.output_item.done')\n",
      "ResponseCompletedEvent(response=Response(id='resp_6899a27338d08198b009237fc875dc790c083d2351948b56', created_at=1754899059.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4.1-mini-2025-04-14', object='response', output=[ResponseOutputMessage(id='msg_6899a2736ea0819899639402af56dd710c083d2351948b56', content=[ResponseOutputText(annotations=[], text='Hello! How can I assist you today?', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=9, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=10, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=19), user=None, store=True), sequence_number=16, type='response.completed')\n"
     ]
    }
   ],
   "source": [
    "from langfuse.openai import AsyncOpenAI,OpenAI\n",
    "client = AsyncOpenAI()\n",
    "\n",
    "stream = await client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"say hello\",\n",
    "        },\n",
    "    ],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "async for event in stream:\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "310c1e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResponseCreatedEvent(response=Response(id='resp_68999cbd6a1c8199ba4922e8bfcb67b50d525586bb003571', created_at=1754897597.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4.1-mini-2025-04-14', object='response', output=[], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), safety_identifier=None, service_tier='auto', status='in_progress', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=None, user=None, store=True), sequence_number=0, type='response.created')\n",
      "ResponseInProgressEvent(response=Response(id='resp_68999cbd6a1c8199ba4922e8bfcb67b50d525586bb003571', created_at=1754897597.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4.1-mini-2025-04-14', object='response', output=[], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), safety_identifier=None, service_tier='auto', status='in_progress', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=None, user=None, store=True), sequence_number=1, type='response.in_progress')\n",
      "ResponseOutputItemAddedEvent(item=ResponseOutputMessage(id='msg_68999cbdc62881999e9023312f55f0680d525586bb003571', content=[], role='assistant', status='in_progress', type='message'), output_index=0, sequence_number=2, type='response.output_item.added')\n",
      "ResponseContentPartAddedEvent(content_index=0, item_id='msg_68999cbdc62881999e9023312f55f0680d525586bb003571', output_index=0, part=ResponseOutputText(annotations=[], text='', type='output_text', logprobs=[]), sequence_number=3, type='response.content_part.added')\n",
      "ResponseTextDeltaEvent(content_index=0, delta='Hello', item_id='msg_68999cbdc62881999e9023312f55f0680d525586bb003571', logprobs=[], output_index=0, sequence_number=4, type='response.output_text.delta', obfuscation='9XKHzqvZ9d7')\n",
      "ResponseTextDeltaEvent(content_index=0, delta='!', item_id='msg_68999cbdc62881999e9023312f55f0680d525586bb003571', logprobs=[], output_index=0, sequence_number=5, type='response.output_text.delta', obfuscation='3Rmsnke3iFczvtq')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' How', item_id='msg_68999cbdc62881999e9023312f55f0680d525586bb003571', logprobs=[], output_index=0, sequence_number=6, type='response.output_text.delta', obfuscation='pAsjmtbK7qlG')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' can', item_id='msg_68999cbdc62881999e9023312f55f0680d525586bb003571', logprobs=[], output_index=0, sequence_number=7, type='response.output_text.delta', obfuscation='bq78F73OrtgJ')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' I', item_id='msg_68999cbdc62881999e9023312f55f0680d525586bb003571', logprobs=[], output_index=0, sequence_number=8, type='response.output_text.delta', obfuscation='gMTbLuHHOHRDsd')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' assist', item_id='msg_68999cbdc62881999e9023312f55f0680d525586bb003571', logprobs=[], output_index=0, sequence_number=9, type='response.output_text.delta', obfuscation='71nzRJ306')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' you', item_id='msg_68999cbdc62881999e9023312f55f0680d525586bb003571', logprobs=[], output_index=0, sequence_number=10, type='response.output_text.delta', obfuscation='YI65wxBHIR9H')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' today', item_id='msg_68999cbdc62881999e9023312f55f0680d525586bb003571', logprobs=[], output_index=0, sequence_number=11, type='response.output_text.delta', obfuscation='JNS0BJgXtw')\n",
      "ResponseTextDeltaEvent(content_index=0, delta='?', item_id='msg_68999cbdc62881999e9023312f55f0680d525586bb003571', logprobs=[], output_index=0, sequence_number=12, type='response.output_text.delta', obfuscation='M2Tt1DUe4zzlCWm')\n",
      "ResponseTextDoneEvent(content_index=0, item_id='msg_68999cbdc62881999e9023312f55f0680d525586bb003571', logprobs=[], output_index=0, sequence_number=13, text='Hello! How can I assist you today?', type='response.output_text.done')\n",
      "ResponseContentPartDoneEvent(content_index=0, item_id='msg_68999cbdc62881999e9023312f55f0680d525586bb003571', output_index=0, part=ResponseOutputText(annotations=[], text='Hello! How can I assist you today?', type='output_text', logprobs=[]), sequence_number=14, type='response.content_part.done')\n",
      "ResponseOutputItemDoneEvent(item=ResponseOutputMessage(id='msg_68999cbdc62881999e9023312f55f0680d525586bb003571', content=[ResponseOutputText(annotations=[], text='Hello! How can I assist you today?', type='output_text', logprobs=[])], role='assistant', status='completed', type='message'), output_index=0, sequence_number=15, type='response.output_item.done')\n",
      "ResponseCompletedEvent(response=Response(id='resp_68999cbd6a1c8199ba4922e8bfcb67b50d525586bb003571', created_at=1754897597.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4.1-mini-2025-04-14', object='response', output=[ResponseOutputMessage(id='msg_68999cbdc62881999e9023312f55f0680d525586bb003571', content=[ResponseOutputText(annotations=[], text='Hello! How can I assist you today?', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=9, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=10, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=19), user=None, store=True), sequence_number=16, type='response.completed')\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "stream = client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"say hello\",\n",
    "        },\n",
    "    ],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for event in stream:\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f654890",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xagent.utils.tool_decorator import function_tool\n",
    "\n",
    "@function_tool()\n",
    "def calculate_square(n: int) -> int:\n",
    "    \"\"\"Calculate square of a number (CPU-intensive).\"\"\"\n",
    "    import time\n",
    "    time.sleep(0.1)  # Simulate CPU work\n",
    "    return n * n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc3b25d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResponseCreatedEvent(response=Response(id='resp_68999cc00bb8819b8c384563d06a47eb0eda0af6f5b8127e', created_at=1754897600.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4.1-mini-2025-04-14', object='response', output=[], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[FunctionTool(name='calculate_square', parameters={'type': 'object', 'properties': {'n': {'type': 'integer'}}, 'required': ['n'], 'additionalProperties': False}, strict=True, type='function', description='Calculate square of a number (CPU-intensive).')], top_p=1.0, background=False, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), safety_identifier=None, service_tier='auto', status='in_progress', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=None, user=None, store=True), sequence_number=0, type='response.created')\n",
      "ResponseInProgressEvent(response=Response(id='resp_68999cc00bb8819b8c384563d06a47eb0eda0af6f5b8127e', created_at=1754897600.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4.1-mini-2025-04-14', object='response', output=[], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[FunctionTool(name='calculate_square', parameters={'type': 'object', 'properties': {'n': {'type': 'integer'}}, 'required': ['n'], 'additionalProperties': False}, strict=True, type='function', description='Calculate square of a number (CPU-intensive).')], top_p=1.0, background=False, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), safety_identifier=None, service_tier='auto', status='in_progress', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=None, user=None, store=True), sequence_number=1, type='response.in_progress')\n",
      "ResponseOutputItemAddedEvent(item=ResponseFunctionToolCall(arguments='', call_id='call_LMc1ocJsH2RAKmseumB4wXaT', name='calculate_square', type='function_call', id='fc_68999cc0add4819b831842f11a59355d0eda0af6f5b8127e', status='in_progress'), output_index=0, sequence_number=2, type='response.output_item.added')\n",
      "ResponseFunctionCallArgumentsDeltaEvent(delta='{\"', item_id='fc_68999cc0add4819b831842f11a59355d0eda0af6f5b8127e', output_index=0, sequence_number=3, type='response.function_call_arguments.delta', obfuscation='M11iTECcxCnpSI')\n",
      "ResponseFunctionCallArgumentsDeltaEvent(delta='n', item_id='fc_68999cc0add4819b831842f11a59355d0eda0af6f5b8127e', output_index=0, sequence_number=4, type='response.function_call_arguments.delta', obfuscation='CyO1vDk0eZDGPvz')\n",
      "ResponseFunctionCallArgumentsDeltaEvent(delta='\":', item_id='fc_68999cc0add4819b831842f11a59355d0eda0af6f5b8127e', output_index=0, sequence_number=5, type='response.function_call_arguments.delta', obfuscation='bQfgc5FulKHtoY')\n",
      "ResponseFunctionCallArgumentsDeltaEvent(delta='5', item_id='fc_68999cc0add4819b831842f11a59355d0eda0af6f5b8127e', output_index=0, sequence_number=6, type='response.function_call_arguments.delta', obfuscation='6Z66v46npjLcOJV')\n",
      "ResponseFunctionCallArgumentsDeltaEvent(delta='}', item_id='fc_68999cc0add4819b831842f11a59355d0eda0af6f5b8127e', output_index=0, sequence_number=7, type='response.function_call_arguments.delta', obfuscation='zTYtzVCRxZvUppY')\n",
      "ResponseFunctionCallArgumentsDoneEvent(arguments='{\"n\":5}', item_id='fc_68999cc0add4819b831842f11a59355d0eda0af6f5b8127e', output_index=0, sequence_number=8, type='response.function_call_arguments.done')\n",
      "ResponseOutputItemDoneEvent(item=ResponseFunctionToolCall(arguments='{\"n\":5}', call_id='call_LMc1ocJsH2RAKmseumB4wXaT', name='calculate_square', type='function_call', id='fc_68999cc0add4819b831842f11a59355d0eda0af6f5b8127e', status='completed'), output_index=0, sequence_number=9, type='response.output_item.done')\n",
      "ResponseCompletedEvent(response=Response(id='resp_68999cc00bb8819b8c384563d06a47eb0eda0af6f5b8127e', created_at=1754897600.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4.1-mini-2025-04-14', object='response', output=[ResponseFunctionToolCall(arguments='{\"n\":5}', call_id='call_LMc1ocJsH2RAKmseumB4wXaT', name='calculate_square', type='function_call', id='fc_68999cc0add4819b831842f11a59355d0eda0af6f5b8127e', status='completed')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[FunctionTool(name='calculate_square', parameters={'type': 'object', 'properties': {'n': {'type': 'integer'}}, 'required': ['n'], 'additionalProperties': False}, strict=True, type='function', description='Calculate square of a number (CPU-intensive).')], top_p=1.0, background=False, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=48, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=15, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=63), user=None, store=True), sequence_number=10, type='response.completed')\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "stream = client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the square of 5?\",\n",
    "        },\n",
    "    ],\n",
    "    tools=[calculate_square.tool_spec],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "events = []\n",
    "for event in stream:\n",
    "    events.append(event)\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b735cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "events[-1].response.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e67dcf1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n': 5}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# events[2].item.type\n",
    "events[-1].response.output[0].type\n",
    "import json\n",
    "json.loads(getattr(events[-1].response.output[0], \"arguments\", \"{}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59024ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response.created ResponseCreatedEvent(response=Response(id='resp_68999dce15548198b415f2cb263fbc080714f1eacf687e9c', created_at=1754897870.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4.1-mini-2025-04-14', object='response', output=[], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[FunctionTool(name='calculate_square', parameters={'type': 'object', 'properties': {'n': {'type': 'integer'}}, 'required': ['n'], 'additionalProperties': False}, strict=True, type='function', description='Calculate square of a number (CPU-intensive).')], top_p=1.0, background=False, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), safety_identifier=None, service_tier='auto', status='in_progress', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=None, user=None, store=True), sequence_number=0, type='response.created')\n",
      "response.in_progress ResponseInProgressEvent(response=Response(id='resp_68999dce15548198b415f2cb263fbc080714f1eacf687e9c', created_at=1754897870.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4.1-mini-2025-04-14', object='response', output=[], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[FunctionTool(name='calculate_square', parameters={'type': 'object', 'properties': {'n': {'type': 'integer'}}, 'required': ['n'], 'additionalProperties': False}, strict=True, type='function', description='Calculate square of a number (CPU-intensive).')], top_p=1.0, background=False, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), safety_identifier=None, service_tier='auto', status='in_progress', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=None, user=None, store=True), sequence_number=1, type='response.in_progress')\n",
      "response.output_item.added ResponseOutputItemAddedEvent(item=ResponseOutputMessage(id='msg_68999dce92508198aac6cbe94f2f9c750714f1eacf687e9c', content=[], role='assistant', status='in_progress', type='message'), output_index=0, sequence_number=2, type='response.output_item.added')\n",
      "response.content_part.added ResponseContentPartAddedEvent(content_index=0, item_id='msg_68999dce92508198aac6cbe94f2f9c750714f1eacf687e9c', output_index=0, part=ResponseOutputText(annotations=[], text='', type='output_text', logprobs=[]), sequence_number=3, type='response.content_part.added')\n",
      "response.output_text.delta Hello\n",
      "response.output_text.delta !\n",
      "response.output_text.delta  How\n",
      "response.output_text.delta  can\n",
      "response.output_text.delta  I\n",
      "response.output_text.delta  assist\n",
      "response.output_text.delta  you\n",
      "response.output_text.delta  today\n",
      "response.output_text.delta ?\n",
      "response.output_text.done ResponseTextDoneEvent(content_index=0, item_id='msg_68999dce92508198aac6cbe94f2f9c750714f1eacf687e9c', logprobs=[], output_index=0, sequence_number=13, text='Hello! How can I assist you today?', type='response.output_text.done')\n",
      "response.content_part.done ResponseContentPartDoneEvent(content_index=0, item_id='msg_68999dce92508198aac6cbe94f2f9c750714f1eacf687e9c', output_index=0, part=ResponseOutputText(annotations=[], text='Hello! How can I assist you today?', type='output_text', logprobs=[]), sequence_number=14, type='response.content_part.done')\n",
      "response.output_item.done ResponseOutputItemDoneEvent(item=ResponseOutputMessage(id='msg_68999dce92508198aac6cbe94f2f9c750714f1eacf687e9c', content=[ResponseOutputText(annotations=[], text='Hello! How can I assist you today?', type='output_text', logprobs=[])], role='assistant', status='completed', type='message'), output_index=0, sequence_number=15, type='response.output_item.done')\n",
      "response.completed ResponseCompletedEvent(response=Response(id='resp_68999dce15548198b415f2cb263fbc080714f1eacf687e9c', created_at=1754897870.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4.1-mini-2025-04-14', object='response', output=[ResponseOutputMessage(id='msg_68999dce92508198aac6cbe94f2f9c750714f1eacf687e9c', content=[ResponseOutputText(annotations=[], text='Hello! How can I assist you today?', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[FunctionTool(name='calculate_square', parameters={'type': 'object', 'properties': {'n': {'type': 'integer'}}, 'required': ['n'], 'additionalProperties': False}, strict=True, type='function', description='Calculate square of a number (CPU-intensive).')], top_p=1.0, background=False, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=42, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=11, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=53), user=None, store=True), sequence_number=16, type='response.completed')\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "stream = client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"say hello\",\n",
    "        },\n",
    "    ],\n",
    "    tools=[calculate_square.tool_spec],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "events = []\n",
    "for event in stream:\n",
    "    events.append(event)\n",
    "    print(event.type, event.delta if event.type == 'response.output_text.delta' else event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c0948e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158b6c95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
